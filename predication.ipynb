{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet18_Weights\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75da014707cb607c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MultiTaskCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiTaskCNN, self).__init__()\n",
    "        # Load a pre-trained model as a feature extractor\n",
    "        base_model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        self.features = nn.Sequential(*list(base_model.children())[:-2])  # Exclude the last fc layer\n",
    "\n",
    "        self.bbox_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(base_model.fc.in_features, 4)  # 4 outputs for bbox (x, y, width, height)\n",
    "        )\n",
    "\n",
    "        self.classifier_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(base_model.fc.in_features, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        bbox = self.bbox_head(x)\n",
    "        class_logits = self.classifier_head(x)\n",
    "        return bbox, class_logits\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a6c561db0667384"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_model(file_name, num_classes, directory='PyTorchModel'):\n",
    "    path = os.path.join(directory, file_name)\n",
    "    # Initialize the model\n",
    "    model = MultiTaskCNN(num_classes=num_classes)\n",
    "    # Load the model state dictionary\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.to(device)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a70661c37470a266"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db8a20697c0353ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define paths\n",
    "base_dir = 'img_celeba'\n",
    "bbox_excel_path = os.path.join(base_dir, 'list_bbox_celeba.txt')\n",
    "identity_txt_path = os.path.join(base_dir, 'identity_CelebA.txt')\n",
    "images_dir = os.path.join(base_dir, 'img_celeba')\n",
    "\n",
    "# Read the Excel file for bounding boxes\n",
    "bbox_df = pd.read_csv(bbox_excel_path, sep='\\s+', skiprows=1)\n",
    "\n",
    "# Read the identity file\n",
    "identity_df = pd.read_csv(identity_txt_path, sep=\" \", header=None, names=['image_id', 'identity'])\n",
    "# Path to the evaluation partition file\n",
    "eval_partition_path = os.path.join(base_dir, 'list_eval_partition.txt')\n",
    "\n",
    "# Read the evaluation partition file\n",
    "eval_partition_df = pd.read_csv(eval_partition_path, sep='\\s+',\n",
    "                                header=None, names=['image_id', 'evaluation_status'])\n",
    "\n",
    "# Merge the evaluation partition data with the bounding boxes and identity data\n",
    "merged_df = pd.merge(bbox_df, identity_df, on='image_id')\n",
    "merged_df = pd.merge(merged_df, eval_partition_df, on='image_id')\n",
    "\n",
    "# Split the merged data into training, validation, and testing datasets\n",
    "train_df = merged_df[merged_df['evaluation_status'] == 0].drop(columns=['evaluation_status'])\n",
    "val_df = merged_df[merged_df['evaluation_status'] == 1].drop(columns=['evaluation_status'])\n",
    "test_df = merged_df[merged_df['evaluation_status'] == 2].drop(columns=['evaluation_status'])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "945b13b20cdbec4b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_classes = len(train_df['identity'].unique())\n",
    "file_name = 'multi_task_cnn_model.pth'\n",
    "# When you need to load the model\n",
    "model = load_model(file_name, num_classes)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dfaf051b29b2616"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize images\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "de9f6ec8acd46ff1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
